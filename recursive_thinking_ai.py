import openai
import os
import re
import pandas as pd
from konlpy.tag import Okt
from typing import List, Dict
import json
from datetime import datetime
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class EnhancedRecursiveThinkingChat:
    def __init__(
        self,
        api_key: str = None,
        model: str = "gpt-3.5-turbo",
        system_prompt_file: str = None,
        reference_csv: str = None
    ):
        # API í‚¤ ì„¤ì •
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYì— í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        openai.api_key = self.api_key
        self.model = model
        self.conversation_history: List[Dict] = []

        # í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™” ë° ì°¸ì¡° ë°ì´í„° ë¡œë“œ
        self.morph_analyzer = Okt()
        self.reference_df = None

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
        if system_prompt_file and os.path.exists(system_prompt_file):
            with open(system_prompt_file, encoding="utf-8") as f:
                system_prompt = f.read().strip()
            # ì´ˆê¸° ì§€ì¹¨ì— ê¸€ììˆ˜, í˜•íƒœì†Œìˆ˜, ì´ë¯¸ì§€ì„¤ëª… ì œì™¸ ê·œì¹™ í¬í•¨
            system_prompt += (
                "\n\nì¶”ê°€ ì§€ì¹¨: ì¶œë ¥ë¬¼ì—ì„œ ë§ˆí¬ë‹¤ìš´ ì´ë¯¸ì§€ ì„¤ëª…(ì˜ˆ: ![alt](file.png): ì„¤ëª…) ë¼ì¸ì€ ê¸€ììˆ˜ ë° í˜•íƒœì†Œ ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸í•˜ê³ , "
                "ì œëª©(ê³µë°± í¬í•¨ 40Â±5, ê³µë°± ì œì™¸ 30Â±5)ê³¼ ë³¸ë¬¸(ê³µë°± í¬í•¨ 1763Â±50, ê³µë°± ì œì™¸ 1339Â±50, í˜•íƒœì†Œ 340Â±10)ì„ ë°˜ë“œì‹œ ë§ì¶° ì‘ì„±í•˜ì„¸ìš”."
            )
            self.conversation_history.append({"role": "system", "content": system_prompt})

        # CSV ë°ì´í„° ë¡œë“œ (ì¹´í…Œê³ ë¦¬-íë¦„)
        if reference_csv and os.path.exists(reference_csv):
            df = pd.read_csv(reference_csv, encoding='utf-8-sig')
            df.columns = ['category', 'flow'] + list(df.columns[2:])
            self.reference_df = df[['category', 'flow']]

    def _call_api(
        self,
        messages: List[Dict],
        temperature: float = 0.7,
        stream: bool = True
    ) -> str:
        try:
            resp = openai.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=stream
            )
            if stream:
                full = ""
                for chunk in resp:
                    content = chunk.choices[0].delta.get('content')
                    if content:
                        full += content
                return full
            return resp.choices[0].message.content.strip()
        except Exception as e:
            return f"Error: {e}"

    def _extract_reference_flow(self, user_input: str) -> str:
        if self.reference_df is None:
            return ""
        nouns = self.morph_analyzer.nouns(user_input)
        matched = self.reference_df[self.reference_df.apply(
            lambda row: any(noun in row['category'] or noun in row['flow'] for noun in nouns), axis=1
        )]
        if matched.empty:
            return ""
        flows = matched['flow'].dropna().tolist()
        return "ì°¸ê³  íë¦„ (ìœ ì‚¬í•œ ì¦ìƒ-ì§„ë£Œ-ì¹˜ë£Œ):\n" + "\n".join(f"- {f}" for f in flows)

    def _strip_image_lines(self, text: str) -> str:
        # ì´ë¯¸ì§€ ì„¤ëª… ë¼ì¸ ì œê±° (!\[...\]\(...\): ...)
        lines = text.split("\n")
        filtered = [ln for ln in lines if not re.match(r"^!\[.*?\]\(.*?\):.*", ln)]
        return "\n".join(filtered)

    def think_and_respond(self, user_input: str) -> Dict:
        messages = list(self.conversation_history)
        # ì°¸ì¡° íë¦„
        ref = self._extract_reference_flow(user_input)
        if ref:
            messages.append({"role": "system", "content": ref})
        # ì‚¬ìš©ì ë©”ì‹œì§€
        messages.append({"role": "user", "content": user_input})

        # API í˜¸ì¶œ (ëª¨ë¸ì´ ì§€ì¹¨ì— ë”°ë¼ ê¸¸ì´ ë§ì¶¤í•˜ë„ë¡)
        response = self._call_api(messages, stream=True)

        # ê³„ì‚°ìš© í…ìŠ¤íŠ¸: ì´ë¯¸ì§€ ë¼ì¸ ì œì™¸
        calc_text = self._strip_image_lines(response)
        # ë©”ì‹œì§€ì— ê³„ì‚°ëœ ê¸¸ì´ ìš”ì•½(ë””ë²„ê¹…ìš©, í•„ìš”ì‹œ ì œê±°)
        title_body = calc_text.replace('# ', '')
        # ëŒ€í™” ì´ë ¥ ì—…ë°ì´íŠ¸
        self.conversation_history.append({"role": "user", "content": user_input})
        self.conversation_history.append({"role": "assistant", "content": response})
        return {"response": response, "_calc_text": title_body}


def main():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("Error: OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    chat = EnhancedRecursiveThinkingChat(
        api_key=api_key,
        model="gpt-3.5-turbo",
        system_prompt_file="prompt_test.txt",
        reference_csv="test_write_data5.csv"
    )
    print("Chat ì‹œì‘ (exit ì…ë ¥ ì‹œ ì¢…ë£Œ)")
    while True:
        inp = input("You: ").strip()
        if inp.lower() == "exit":
            break
        if not inp:
            continue
        result = chat.think_and_respond(inp)
        print(f"\nğŸ¤– AI FINAL RESPONSE:\n{result['response']}\n")

if __name__ == "__main__":
    main()
